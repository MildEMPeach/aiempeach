#!/usr/bin/env python3
import os
import sys
import argparse
from typing import List, Dict, Any
from langchain_deepseek import ChatDeepSeek
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.callbacks import BaseCallbackHandler
from dotenv import load_dotenv

try:
    load_dotenv()
except Exception as e:
    print(f"Error loading .env file: {e}")

class StreamingCallbackHandler(BaseCallbackHandler):
    """å®æ—¶æµå¼è¾“å‡ºå›è°ƒå¤„ç†å™¨"""
    
    def __init__(self):
        self.text = ""
        self.buffer = ""
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """å½“æ¥æ”¶åˆ°æ–°çš„tokenæ—¶è°ƒç”¨"""
        try:
            # ç¡®ä¿tokenæ˜¯å­—ç¬¦ä¸²æ ¼å¼
            if token is not None:
                # å¤„ç†å¯èƒ½çš„ç¼–ç é—®é¢˜
                if isinstance(token, bytes):
                    token = token.decode('utf-8', errors='ignore')
                
                # ç¼“å†²è¾“å‡ºä»¥é¿å…æ˜¾ç¤ºé—®é¢˜
                self.buffer += token
                self.text += token
                
                # å®æ—¶è¾“å‡º
                sys.stdout.write(token)
                sys.stdout.flush()
        except Exception as e:
            # é™é»˜å¤„ç†ç¼–ç é”™è¯¯ï¼Œé¿å…ä¸­æ–­æµå¼è¾“å‡º
            pass
    
    def on_llm_end(self, response, **kwargs) -> None:
        """LLMå“åº”ç»“æŸæ—¶è°ƒç”¨"""
        # ç¡®ä¿è¾“å‡ºå®Œæ•´
        if self.buffer:
            sys.stdout.flush()
    
    def reset(self):
        """é‡ç½®å¤„ç†å™¨çŠ¶æ€"""
        self.text = ""
        self.buffer = ""

class AIEmpeach:
    def __init__(self, model: str = "deepseek-chat"):
        """åˆå§‹åŒ–AIåŠ©æ‰‹"""
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            print("âŒ é”™è¯¯: è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
            sys.exit(1)
        
        self.model = model
        self.llm = ChatDeepSeek(
            model=model,
            api_key=self.api_key,
            streaming=True,
            temperature=0.7
        )
        self.conversation_history: List[Dict[str, Any]] = []
        self.streaming_handler = StreamingCallbackHandler()
        
    def add_system_message(self):
        """æ·»åŠ ç³»ç»Ÿæç¤ºæ¶ˆæ¯"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„å‘½ä»¤è¡ŒåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·å¤„ç†å„ç§æŠ€æœ¯é—®é¢˜ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š
1. æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯
2. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡º
3. å¯¹äºä»£ç ç›¸å…³é—®é¢˜ï¼Œæä¾›å…·ä½“çš„è§£å†³æ–¹æ¡ˆ
4. æ”¯æŒä¸­æ–‡äº¤æµï¼Œè¯­è¨€è‡ªç„¶æµç•…
5. å½“ç”¨æˆ·æä¾›æ–‡ä»¶å†…å®¹æˆ–å‘½ä»¤è¾“å‡ºæ—¶ï¼Œä»”ç»†åˆ†æå¹¶ç»™å‡ºä¸“ä¸šå»ºè®®"""
        
        self.conversation_history.append({"role": "system", "content": system_prompt})
    
    def process_pipe_input(self, question: str = None) -> str:
        """å¤„ç†ç®¡é“è¾“å…¥"""
        if not sys.stdin.isatty():
            # ä»ç®¡é“è¯»å–è¾“å…¥
            pipe_content = sys.stdin.read().strip()
            if pipe_content:
                if question:
                    return f"ä»¥ä¸‹æ˜¯è¾“å…¥çš„å†…å®¹ï¼š\n\n{pipe_content}\n\né—®é¢˜ï¼š{question}"
                else:
                    return f"è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼š\n\n{pipe_content}"
        return question
    
    def get_response_stream(self, message: str) -> str:
        """è·å–æµå¼å“åº”"""
        # æ„å»ºæ¶ˆæ¯å†å²
        messages = []
        
        # æ·»åŠ å†å²æ¶ˆæ¯
        for msg in self.conversation_history:
            if msg["role"] == "system":
                messages.append(SystemMessage(content=msg["content"]))
            elif msg["role"] == "human":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                messages.append(AIMessage(content=msg["content"]))
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append(HumanMessage(content=message))
        
        # é‡ç½®æµå¼å¤„ç†å™¨
        self.streaming_handler.reset()
        
        try:
            # æµå¼è°ƒç”¨
            response = self.llm.invoke(
                messages,
                config={"callbacks": [self.streaming_handler]}
            )
            
            # è·å–å®Œæ•´å“åº”å†…å®¹
            if hasattr(response, 'content'):
                full_response = response.content
            else:
                # å¦‚æœresponseæ²¡æœ‰contentå±æ€§ï¼Œä½¿ç”¨æµå¼å¤„ç†å™¨æ”¶é›†çš„æ–‡æœ¬
                full_response = self.streaming_handler.text or str(response)
            
            # ç¡®ä¿è¾“å‡ºå®Œæ•´
            self.streaming_handler.on_llm_end(response)
            
            return full_response
            
        except KeyboardInterrupt:
            print("\nâš ï¸ å“åº”è¢«ç”¨æˆ·ä¸­æ–­")
            return "å“åº”è¢«ä¸­æ–­"
        except Exception as e:
            error_msg = f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}"
            print(f"\n{error_msg}")
            return error_msg
    
    def add_to_history(self, role: str, content: str):
        """æ·»åŠ å¯¹è¯åˆ°å†å²è®°å½•"""
        self.conversation_history.append({"role": role, "content": content})
    
    def interactive_mode(self):
        """äº¤äº’å¼å¯¹è¯æ¨¡å¼"""
        print("ğŸ¤– AIEmpeach - æ™ºèƒ½å‘½ä»¤è¡ŒåŠ©æ‰‹")
        print(f"ğŸ“¡ ä½¿ç”¨æ¨¡å‹: {self.model}")
        print("ğŸ’¬ å¼€å§‹å¯¹è¯å§ï¼(è¾“å…¥ 'exit', 'quit', 'q' é€€å‡º)")
        print("=" * 50)
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        self.add_system_message()
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ’­ ä½ : ").strip()
                
                # æ£€æŸ¥é€€å‡ºå‘½ä»¤
                if user_input.lower() in ['exit', 'quit', 'q', 'bye']:
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
                
                if not user_input:
                    continue
                
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
                self.add_to_history("human", user_input)
                
                # è·å–AIå“åº”
                print(f"\nğŸ¤– AIEmpeach: ", end='', flush=True)
                response = self.get_response_stream(user_input)
                print()  # æ¢è¡Œ
                
                # æ·»åŠ AIå“åº”åˆ°å†å²
                self.add_to_history("assistant", response)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except EOFError:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ğŸ¤– AIEmpeach - åŸºäºDeepSeek APIçš„æ™ºèƒ½å‘½ä»¤è¡ŒåŠ©æ‰‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python aiempeach.py                    # äº¤äº’æ¨¡å¼
  cat file.txt | python aiempeach.py -q "åˆ†æè¿™ä¸ªæ–‡ä»¶"  # ç®¡é“æ¨¡å¼
  python aiempeach.py -m deepseek-reasoner  # ä½¿ç”¨æ¨ç†æ¨¡å‹
        """
    )
    
    parser.add_argument(
        '-m', '--model',
        type=str,
        default='deepseek-chat',
        choices=['deepseek-chat', 'deepseek-reasoner'],
        help='é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤: deepseek-chat)'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºAIåŠ©æ‰‹å®ä¾‹
    ai = AIEmpeach(model=args.model)
    ai.interactive_mode()

if __name__ == "__main__":
    main()
